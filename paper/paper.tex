% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does  not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes}

\usepackage{proof}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{stmaryrd}

\newcommand{\cross}{\otimes{}}

\usepackage[T1]{fontenc}

\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\begin{document}

%don't want date printed
\date{\today}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf New Static Analysis Techniques to Detect Entropy Failure Vulnerabilities in Modern Software Projects}

%for single author (just remove % characters)
\author{
{\rm Rushi Shah}
\and
{\rm Andrew Russell}
}

\maketitle

\begin{abstract}
 Test abstract
\end{abstract}

\section{Introduction}

One common misuse of cryptography is the misuse of entropy. Without proper random inputs, many cryptographic algorithms
are vulnerable to basic forms of cryptanalysis. Some cryptographic schemes, such as DSA, can even disclose long-term secrets
such as the signing key when the random per-message input is low entropy, made public, or nonunique.

We plan to use data dependency tools to determine how entropic inputs in a given program are used by various cryptographic algorithms. That will allow us to identify if and when entropy is too low or is misused. We plan to produce this as a code integration tool for developers to use as part of a compiler toolchain.
Our tool will seek to generate an error report from source code using notions of taint analysis. 

For this project we consider codebases that maintain version history, in the hopes that we can employ static analysis techniques across program versions to infer more information about how entropy is being used; 
our primary goal is to identify bugs that are introduced to existing codebases. This may prove to be especially helpful since naive taint analysis can provide mere overapproximations of data dependency for a given program and may generate many false alarms for programmers in a professional development setting.

\subsection{Related Work}

Differential assertion checking, verification modulo versions, relational verification using product programs, secure information flow as a safety problem

\section{Preliminaries}

\subsection{Demonstrative Language}

We will build our tool for a language consisting of a small set of semantic rules (Figure \ref{fig:semrules}).

\begin{figure}
\label{fig:semrules}
\caption{}
\[
	\begin{array}{l l c l}
		\emph{Statement} & S & := & 
			\ \ A \\
			& & & |~ S_1\ ;\ S_2 \\
			& & & |~ \emph{if }p\emph{ then } S_1 \emph{ else } S_2 \\
			& & & |~ \emph{while }p\emph{ } S \\
		\emph{Predicate} & p &:=& \top ~~|~~ \bot ~~|~~ A ~~|~~ \lnot p ~~|~~ p \odot p \\
		\emph{Operator} & \odot &:=& \land ~~|~~ \lor \\
	\end{array}
\]
\end{figure}

Our results can be extended in a straightforward manner to an industrial language such as C, and we do so for our evaluation (Section \ref{sec:eval}).

\subsection{Taint Analysis}

Taint analysis is a standard program analysis technique, typically used to detect security vulnerabilities in either a static or dynamic manner. 
We restrict our focus to the static variant. We define a taint analysis algorithm as follows:

\begin{itemize}
    \item $\Gamma \gets \mathsf{Taint}_{S,L}(\phi, T, \Sigma, Z, P)$: Takes as input an initial assignment $\phi$ of some taint sets $T = \{\tau_i\}$ to 
    a set of sources $\Sigma = \{\sigma_i\}$, and an input program $P$. Outputs an 
    assignment $\Gamma$ of statements $s_i$ in the program $P$ to taint sets $\tau_i \in T$ according to the taint propagation semantics $S$ for programming
    language $L$.
\end{itemize}


An example of static taint analysis is to determine if unsanitized user inputs are ever provided to vulnerable functions, such as SQL commands or
a webpage templating function. In our case we wish to ensure that entropy-sensitive inputs to cryptographic functions (sinks) can be
traced back to a high-entropy source such as *nix's \texttt{/dev/urandom}.

\subsection{$k$-safety properties}

As opposed to a safety property of a program (for example, ``variable $x$ is always positive'' or ``pointer $p$ is never null''), which requires
the absence of errors in a single program trace \cite{alpern1987recognizing}, a $k$-safety property of a program requires the absence of erroneous interactions between $k$
traces of the same program \cite{sousa2016cartesian}. A program property such as symmetry is a $2$-safety property.


\subsection{Predicate Abstraction}

Predicate abstraction is a specialized form of abstract interpretation that can be used for checking $1$-safety properties of programs
\cite{flanagan2002predicate}. Abstract interpretation is a static analysis technique for programs that allows a verifier to, in some cases, 
automatically infer properties such as loop invariants. Formally we have:

\begin{itemize}
    \item $b \gets \mathsf{Verify}_{L}(\pi, P)$: Takes as input a $1$-safety property $\pi$ and a program $P$ and outputs an accepting bit $\top$ if
    $P$ satisfies the safety property, and otherwise outputs a rejecting bit $\bot$ or fails to terminate otherwise.
\end{itemize}

CPAchecker \cite{beyer2011cpachecker} is an example of a state-of-the-art predicate abstraction verifier for the C programming language. In this work
we are interested in the safety property of equality. We note that due to inherent hardness results such as NP-hardness and undecidability, predicate
abstraction verifiers are based on heuristic methods and are not guaranteed to run in polynomial time, or even terminate.

\subsection{Product Programs}

The product $P_1 \times P_2$ of two programs $P_1$ and $P_2$ is not an entirely well-defined concept. In the most general sense, the product $P_1 \times P_2$ of 
two programs $P_1$ and $P_2$ is used to verify
relations between the programs, such as equivalence \cite{barthe2011relational}. Product programs have also been used to analyze different runs of the same program. 
The product program $P_1 \times P_2$ is semantically equivalent to the sequential composition $P_1; P_2$, but such that we can prove useful 
safety properties of $P_1 \times P_2$ that would be difficult to 
prove with standard techniques on $P_1$, $P_2$, or $P_1; P_2$.

For our purposes we simply require that $P_1 \times P_2$ is semantically
equivalent to the sequential composition $P_1\ ;\ P_2$ of the two programs. Our goal in using the concept of product programs is to aid the predicate abstraction
verifier. 

\section{Our Approach}

Our main approach to this problem is to take two versions $P_1$ and $P_2$ of a program and prove $P_2$ \emph{relative} to $P_1$. We have several
motivations for this approach:

\begin{itemize}
    \item Taint analysis is an (over)approximate solution.
    \item Modern software projects often use version control history, and we can leverage that to give a static verifier more power (heuristically speaking).
\end{itemize}

Let us address the first point.
An initial approach to this problem
might consist of using off-the-shelf taint analysis (we would taint high-entropy sources and confirm that
cryptographic functions receive high-entropy tainted inputs). 
However, taint analysis merely provides an overapproximation to the actual entropy that is
input to a cryptographic algorithm. Consider the program in Figure
\ref{fig:prog1}. The variable $k$ is tainted with high-entropy, but will not contain high-entropy if $f()$ ever evaluates to false.

\begin{figure}
    \label{fig:prog1}
    \caption{Taint analysis overapproximation}
    \begin{center}
    \begin{algorithmic}
        
        \If {$f()$}
        \State $k \gets$ \textsf{read(128, ``/dev/urandom'')}
        \Else
        \State $k \gets$ \textsf{getpid()}
        \EndIf
        \State $\mathsf{ctxt} \gets $ \textsf{AES}$(k,\mathsf{ptxt})$
    \end{algorithmic}
\end{center}
\end{figure}

Now we consider the second point. Since software developers often have access to multiple revisions of a single program, we wish to use this additional information
to do better than simple taint analysis on a single version. This allows for stronger security guarantees at lower cost: a software project can invest
in manually auditing an initial version of its security-critical software, and then use our methods to prove that subsequent versions do not contain entropy
failures provided that this initial version does not (i.e., a \emph{relative} or \emph{differential} notion of security). Additionally, since we expect
program revisions (particularly those touching security-critical components) to be infrequent and small, we can reduce the scope of the verifier's work.

\subsection{A First Attempt}

Given that we wish to attain this differential notion of security, we first address a naive attempt at solving this problem using taint analysis.
Consider the program in Figure \ref{fig:prog2} compared to the program in Figure \ref{fig:prog1}. The taint sets of $k$ in both versions of the program
are equal, however, simply comparing for equality here is \emph{unsound} with respect to our differential notion of security, since for all program traces
in which the first program is secure, all similar program traces in the second program are insecure.

\begin{figure}
    \label{fig:prog2}
    \caption{Taint analysis unsoundness}
    \begin{center}
    \begin{algorithmic}
        \If {$f()$}
        \State $k \gets$ \textsf{getpid()}
        \Else
        \State $k \gets$ \textsf{read(128, ``/dev/urandom'')}
        \EndIf
        \State $\mathsf{ctxt} \gets $ \textsf{AES}$(k,\mathsf{ptxt})$
    \end{algorithmic}
\end{center}
\end{figure}

\subsection{Differential Taint Analysis}

Description of differential taint analysis.

\subsection{Overview}

Our solution proceeds in three primary stages:

\begin{itemize}
    \item \textbf{Instrumentation:} In this step we reduce our taint analysis problem for each program version $P_1$ and $P_2$ to one of $2$-safety.
    Additionally, we run taint analysis on each program to get outputs $\Gamma_1$ and $\Gamma_2$, which we use in the next step.
    \item \textbf{Program synchronization:} Using our environment $\Gamma = \Gamma_1 \cup \Gamma_2$, our instrumented programs $P'_1$ and $P'_2$ from 
    the previous step, we construct the product program $P'_1 \times P'_2$. This converts the $2$-safety problem to one of $1$-safety.
    \item \textbf{Verification:} Finally, we pass $P'_1 \times P'_2$ to an off-the-shelf verifier to check the $1$-safety property to
    prove security.
\end{itemize}

We describe these in more formal detail in the coming sections.

\subsection{Instrumenting Programs for Predicate Abstraction}

	% Take C/C++ project and turn it into our IR. 

	In the instrumentation phase, we take an entire software project, and augment it with the other inputs (like annotations) to prepare it for the static analysis we will perform. Ultimately, our goal is to make assertions about the taintsets of program variables at the sinks. But first, we will individually instrument each version of the software project.

	First we transform the code from its existing state into the language whose semantics we described earlier. We also rename the variables in the second version of the program so their names are disjoint from the variable names in program one. Then, in both programs, we replace the legitimate sources of entropy with labelled constants. We propogate these labelled constants through the program to propagate the taint of the entropy. In the process of doing so, it is possible that a value is tainted by more than one source (which is why we are tracking the taintset). We replace statements that taint a value with two or more sources ($s_1, s_2, \ldots, s_n$) with one of two uninterpreted functions: 

	\begin{enumerate}
		\item $\textsf{preserving}(s_1, s_2, \ldots, s_n)$ if the operation preserves entropy (+, XOR, etc.)
		\item $\textsf{non-preserving}(s_1, s_2, \ldots, s_n)$ if the operation does not preserve entropy (<<, >>, etc.)
	\end{enumerate}

	These uninterpreted functions are inferred to be pure functions over their variables, so they capture the notion of the taintset at that point. This allows us to assert their equality in the program we pass to CPAChecker. 

	Next, we will collect information from the two versions of the program as we transform them that will guide our future inference rules. Namely, we will perform taint analysis on sources to populate the environment $\Gamma$ which marks statements involving tainted variables. $\Gamma \vdash S_1$ if $S_1$ references a variable that is tainted by a source with sufficiently high entropy.  

	% Notice that if $x, y$ are both sufficiently entropic values then $x + y$ is also sufficiently entropic because the audition does not remove the entropy. Therefore addition is replaced with the $\textsf{preserving}$ function call. Contrast this with the left-shift, for example, which will remove entropy from the value. 

    % TODO: talk about what makes us say some functions are preserving and some are not

\textbf{Instrumentation:} Given two program versions $P_1$ and $P_2$, our sources $\Sigma$, and a taint analysis algorithm $\mathsf{Taint}_{S,L}$
     we reduce the taint analysis problem to one of $1$-safety.
    We do this for each $P_k$ by assigning constants $c$ to all sources $\sigma \in \Sigma$, and then where we would propagate taint using the rules $S$ for language $L$
    in statements $s_i$ which is a function of program variables $v_i$ and only of ``entropy preserving" operations (described below) 
    we replace with an uninterpreted function $f(v_1, \ldots, v_j)$. For statements $s'_i$ which are a
    function of any tainted program variables $w_j$ and contain any ``non-entropy preserving operations'' (any operations that are not entropy preserving), we replace
    with an uninterpreted function $g(w_1, \ldots, w_j)$. We output these programs as $P'_1$ and $P'_2$.

Description of instrumentation algorithm.

\subsection{Naive Product Program Inference Rules}

With the instrumented programs, we can construct a product program that is semantically equivalent to the sequential composition of the two programs. However, we would like this product program to be more amenable to reason about for the static analysis tool. To this end, we would like to synchronize the control flow of the two programs as much as possible. 

We present inference rules for composing statements in the two programs $S_1 \cross S_1$ into one program that is semantically equivalent to $S_1\ ;\ S_2$. The most basic inference rule simply involves sequentially composing two atomic statements, which do not involve any control flow to be syncrhonized. Also, because the variables in the two versions of the program have been renamed to be disjoint, we can introduce an inference rule for the commutativity of two statements.  

\begin{figure}
    \label{fig:infrules1}
    \caption{Basic Inference Rules}
    \[
		\begin{array}{c}
			\infer[]{A_1 \cross A_2 \leadsto A_1\ ;\ A_2}{} \\ \\ \\
			\infer[]{S_1 \cross S_2 \leadsto P}{
				S_2 \cross S_1 \leadsto P
			}
        \end{array}
    \]
\end{figure}

Next, we have the inference rule for synchronizing an if-statement with another statement. If $S_1$ is the taken branch, $S_2$ is the not-taken branch, and $S$ is the statement after the entire if-else-statement, then we would like to inject $S$ separately into each branch. This simple transformation is clearly equivalent to the sequential composition of the if-statement and $S$. The benefit of this transformation, however, is that the predicate abstraction tool has more information about the trace taken with which it can reason about product program. 

Finally, we have the inference rule for synchronizing two while loops. The intuition here is that we would like the two loops to operate in lock-step as long as possible. To maintain the equivalence with the sequential composition, we also run the remaining iterations in the leftover loop after the other loop's condition no longer holds.

\begin{figure}
    \label{fig:infrules2}
    \caption{Conditional and Loop Inference Rules}
    \[
		\begin{array}{c}
			\infer[]{if(p)\ then\ S_1\ else\ S_2 \cross S \leadsto P}{
				\text{$S_1 \cross S \leadsto S_1'$} \\
				\text{$S_2 \cross S \leadsto S_2'$} \\
				\text{$P = if(p)\ then\ S_1'\ else\ S_2'$}
			} \\ \\ \\
			\infer[]{while(p_1)\ S_1 \cross while(p_2)\ S_2 \leadsto P_0\ \cross\ P_1\ ;\ P_2}{
				\text{$P_0 = while(p_1 \land p_2)\ S_1\ ;\ S_2$} \\
				\text{$P_1 = while(p_1)\ S_1$} \\
				\text{$P_2 = while(p_2)\ S_2$}
			}
        \end{array}
    \]
\end{figure}

Although these inference rules are semantically equivalent to the sequential composition, and clearly provide benefit to CPAChecker, this proving strength comes at a cost. Namely, the if statements and the while loops lead to an exponential blowup in the size of the product program being reasoned about as a result of the copied statements. 

\subsection{Taint-augmented Inference Rules}

We conjecture that the exponential blowup introduced by the naive inference rules is avoidable in some cases. In particular, our key insight is that we don't need the extra proving power provided by the synchronization in parts of the program that are unrelated to entropy. For these program statements, we can resort to the sequential composition. For example, consider a large software program: only a small portion of the code base will be related to the entropy. Therefore, we should concentrate the bulk of our analysis on this small portion of the code. 

We define these ``unrelated'' statements to be the ones that are not tainted by any legitimate entropy source. This is reasonable because our ultimate assertions we would like to prove will only be over the tainted variables. Thus, we can use the $\Gamma$ environment we constructed in the instrumentation step to augment our inference rules. We say that $\Gamma \vdash S$ if some variable referenced in $S$ is tainted by at least one legitimate source of entropy. Similarly, $\Gamma \nvdash S$ if no variable in the statement is tainted by any legitimate source of entropy. We introduce an optimization inference rule that does not lead to any exponential blowup for statements that are not entailed by $\Gamma$. 

\begin{figure}
    \label{fig:auginfrules1}
    \caption{Augmented Inference Rules}
    \[
		\begin{array}{c}
			\infer[]{\Gamma \vdash S_1 \cross S_2 \leadsto S_1\ ;\ S_2}{
				\Gamma \nvdash S_1 \\
				\Gamma \nvdash S_2
			} \\
		\end{array}
    \]
\end{figure}

Then, we can make the corresponsding changes to our naive inference rules to recognize the $\Gamma$ environment we've introduced. This gives us the following set of augmented inference rules: % TODO: reference to figure

\begin{figure}
    \label{fig:auginfrules2}
    \caption{Augmented Inference Rules}
    \[
		\begin{array}{c}
			\infer[]{\Gamma \vdash A_1 \cross A_2 \leadsto A_1\ ;\ A_2}{} \\ \\ \\
			\infer[]{\Gamma \vdash S_1 \cross S_2 \leadsto P}{
				\Gamma \vdash S_2 \cross S_1 \leadsto P
			} \\ \\ \\
			\infer[]{\Gamma \vdash S_1 \cross S_2 \leadsto S_1\ ;\ S_2}{
				\Gamma \nvdash S_1 \\
				\Gamma \nvdash S_2
			} \\ \\ \\
			\infer[]{\Gamma \vdash if(p)\ then\ S_1\ else\ S_2 \cross S \leadsto P}{
				\text{$\Gamma \vdash S_1 \cross S \leadsto S_1'$} \\
				\text{$\Gamma \vdash S_2 \cross S \leadsto S_2'$} \\
				\text{$P = if(p)\ then\ S_1'\ else\ S_2'$}
			} \\ \\ \\
			\infer[]{\Gamma \vdash while(p_1)\ S_1 \cross while(p_2)\ S_2 \leadsto P_0\ ;\ P_1\ ;\ P_2}{
				\text{$P_0 = while(p_1 \land p_2)\ S_1\ ;\ S_2$} \\
				\text{$P_1 = while(p_1)\ S_1$} \\
				\text{$P_2 = while(p_2)\ S_2$} \\
				\text{$P = if(p)\ then\ S_1'\ else\ S_2'$}
			}
		\end{array}
    \]
\end{figure}

% TODO: Notice that this optimization is only a heuristic. % (taint analysis isn't sufficient given the code snippet Isil mentioned). 

\subsection{Putting it all together}

Description of algorithm using the two subroutines above.

\section{Evaluation}
\label{sec:eval}

% TODO

\section{Conclusion}

In this work we present a new static analysis technique to aid in the prevention of entropy-misuse security vulnerabilities, such as those
found in the Debian OpenSSL and FreeBSD projects.

% \section{Future Work}

% Verify the following conjectures. Prove that a heuristic-based approach is no less powerful than a full product program approach.
% Run this tool on projects in the wild to determine how widespread entropy-misuse bugs are among software projects ``in the wild.''

% \section{Considered Approaches}

% \subsection{Taint Analysis}
% Static code analysis has a history of identifying security vulnerabilities at a source code level. Some examples include SQL injection, cross-site scripting exploits, and buffer overflow attacks. However, there has not been any attempt in the literature to statically analyze source code for cryptographic vulnerabilities stemming from entropy misuse, which we seek to do. We claim that standard static code analysis techniques developed thus far are insufficient for the analysis we would like to perform. 
% The sources of entropy can be tainted standard taint analysis techniques can be used to approximate how the taint propagates. But this approximation may be too coarse to provide useful information to the user. Even with a sufficiently precise taint analysis, it is unclear how to determine the ``correct'' set of sources a cryptographic value should rely on at any point in the program.

% \subsection{Differential Taint Analysis}

% Since we want a stronger notion of taint analysis than a naive approach, we intend to introduce and formalize the concept of ``differential taint analysis." Differential
% taint analysis, in the ideal, will give us more information than simple taint analysis by leveraging 
% the original version of the program as a source of ground truth. This additional information could include reducing programmer annotation work or reduce false positives between versions
% (since taint analysis overapproximates data flow). By viewing the original version of the program as bug-free, we reduce the number of code audits required:
% only the original version of the code would need to be audited, and future versions could rely on our tool to automatically detect bugs that were introduced by refactors.

% \subsection{Product Programs}

% One technique that we have considered toward the construction of differential taint analysis is the notion of a ``product program.'' In the most general sense, the product $P_1 \times P_2$ of two programs $P_1$ and $P_2$ is used to verify
% relations between the programs, such as equivalence. Product programs have also been used to analyze different runs of the same program. 
% The product program $P_1 \times P_2$ is semantically equivalent to the sequential composition $P_1; P_2$, but such that we can prove useful safety properties of $P_1 \times P_2$ that would be difficult to prove with standard techniques on $P_1$, $P_2$, or $P_1; P_2$.

% In our setting, we are not so much interested in proving safety properties of a program $P$ but instead wish to prove that cryptographic values rely on sufficiently many bits of entropy when they are used via taint analysis, 
% which is why we cannot simply leverage existing off-the-shelf product program analysis techniques.

% \subsubsection{Example}

% Consider the following two programs $P_1$ and $P_2$ that are equivalent from a cryptographic point of view, but might have small feature changes. 

% \begin{algorithmic}
% \Function{$P_1$}{}
% \State $s \gets$ entropy
% \State $\vdots$
% \If {$p$}
% \State $c \gets$ AES(s)
% \EndIf
% \State $\vdots$
% \EndFunction
% \\
% \Function{$P_2$}{}
% \State $s \gets$ entropy
% \State $\vdots$
% \If {$p$}
% \State $c \gets$ AES(s)
% \EndIf
% \State $\vdots$
% \EndFunction
% \end{algorithmic}

% where $p$ is some complex predicate that is difficult to reason about, but does not change between $P_1$ and $P_2$ (and no values that $p$ depends on change, either). Then, a safety property about the entropy of the cryptographic values in $c$ would hold in both programs or in neither program. 

% Finally, even with a sufficiently precise taint analysis, it is unclear how to determine the ``correct'' set of sources a cryptographic value should rely on at any point in the program. For example, some programs will use weak entropy on system startup, and increase the entropy in those values, later on. Thus, by running our analysis on two versions of the program, we can use one version as an oracle for the correctness criteria of the other program. In other words, we can use it to infer what the set of taint results should be for any variable at any point in the program.  


\section{Links}

\begin{enumerate}
	\item Debian/OpenSSL Bug 
		\begin{enumerate}
			\item \url{https://www.schneier.com/blog/archives/2008/05/random_number_b.html}
			\item \url{https://research.swtch.com/openssl}
			\item \url{https://freedom-to-tinker.com/2013/09/20/software-transparency-debian-openssl-bug/}
			\item \url{https://www.cs.umd.edu/class/fall2017/cmsc818O/papers/private-keys-public.pdf}
		\end{enumerate}
	\item Data flow
		\begin{enumerate}
			\item \url{https://en.wikipedia.org/wiki/Data-flow_analysis}
			\item \url{https://www.seas.harvard.edu/courses/cs252/2011sp/slides/Lec02-Dataflow.pdf}
		\end{enumerate}
	\item Static Program Analysis
		\begin{enumerate}
            \item \url{https://cs.au.dk/~amoeller/spa/spa.pdf}
            \item \url{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6859783}
		\end{enumerate}
	\item Relational Verification:
		\begin{enumerate}
			\item \url{https://dl.acm.org/citation.cfm?id=2021319}
			\item \url{https://ac.els-cdn.com/S235222081630044X/1-s2.0-S235222081630044X-main.pdf?_tid=076a0492-9cee-4995-9710-bcb3c64b98e0&acdnat=1539815890_178849b4f14af3751e9acb03b238db4d}
			\item \url{https://www.microsoft.com/en-us/research/publication/differential-assertion-checking/}
			\item \url{https://www.microsoft.com/en-us/research/wp-content/uploads/2014/06/paper-1.pdf}
			\item \url{https://www.cs.utexas.edu/~isil/pldi16-chl.pdf}
		\end{enumerate}
	\item Projects to analyze 
		\begin{enumerate}
			\item OpenPGP
			\item BouncyCastle
			\item OpenSSL
			\item GnuPGP
			\item F\# SSL project with proof of correctness
			\item NQSBTLS
			\item Amazon's s2n (signal to noise)
		\end{enumerate}
\end{enumerate}

{\normalsize \bibliographystyle{acm}
\bibliography{refs}}

% We have two motivating examples. First, we would like our tool to be able to detect the issue with the Debian/OpenSSL pseudo-random number generator that was exposed in 2008. 
% Second, we would like to identify potential vulnerabilities in current cryptocurrency wallet code as many cryptocurrency protocols rely on DSA.

% \subsection{Goals}
% We plan to use data dependency tools to determine how entropic inputs in a given program are used by various cryptographic algorithms. 
% That will allow us to identify if and when entropy is too low or is misused. We plan to either produce
% this as a code integration tool for developers to use as part of a compiler toolchain, or use this tool to analyze a large number of codebases
% found ``in the wild,'' such as those written by amateurs.

% Our tool will seek to generate a human-checkable dependency graph from source code
% using taint analysis on functions and function inputs manually specified via annotation by the developer.
% This graph will allow the developer to manually verify that entropy is used properly; a stretch goal 
% of ours would be to automate the identification of a subset of known misuses of entropy.

\end{document}
