% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does  not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes}

\usepackage{proof}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{stmaryrd}

\newcommand{\cross}{\otimes{}}

\usepackage[T1]{fontenc}

\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\begin{document}

%don't want date printed
\date{\today}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf New Static Analysis Techniques to Detect Entropy Failure Vulnerabilities in Modern Software Projects}

%for single author (just remove % characters)
\author{
{\rm Rushi Shah}
\and
{\rm Andrew Russell}
}

\maketitle

\begin{abstract}
    In this work we examine the problem of entropy misuse vulnerabilities in
    security-critical software. Our work approaches the problem from an
    ``ounce of prevention is worth a pound of cure'' perspective; by introducing
    and applying a novel static analysis technique \emph{differential taint analysis},
    we propose a method for catching these bugs. Our approach
    leverages the widespread practice of maintaining software version history for
    modern software projects in order to
     provide augmented heuristics to standard static analysis tools to prove the correctness of
     subsequent versions of programs relative to the correctness of an original version.
     Our contributions include the introduction of differential taint analysis
     as a novel approach to this problem domain, as well as a construction to solve
     the differential taint analysis problem using a reduction to standard static
     analysis techniques.
\end{abstract}

\section{Introduction}

One common misuse of cryptography is the misuse of entropy. Without properly random inputs, many cryptographic schemes
are vulnerable to basic forms of cryptanalysis. Some cryptographic algorithms, such as DSA, can even disclose long-term secrets
such as the signing key when the random per-message input is low entropy, made public, or nonunique. Such frailty implies that
proper entropy use is a necessary requirement for secure systems. These bugs have appeared
in widely-used software projects. We briefly discuss two historical examples.

\subsection{Debian OpenSSL}

\cite{schneier2008}

\subsection{FreeBSD}

\cite{hovav2016}

\subsection{Approaches}

Detecting this class of bug often requires an examination of the source code; 
bugs that lead to completely deterministic outputs
 from cryptographic algorithms can often be caught easily during the manual
 testing of code before it is released. Issues which persist past release
 typically result from low-entropy inputs rather than no-entropy inputs.
 As such, these bugs can be difficult to discover and track down. One solution
 to this problem, manual auditing, does work (historically, a manual
 inspection of source code is how these vulnerabilities are disclosed and fixed).
 However effective, manual audits can be an expensive solution, and altogether 
 infeasible
 for many projects to do often, especially those reliant on community donations and gratis
 developer work. On the other hand, static analysis tools have their own issues:
 due to classic hardness results, static analysis algorithms must rely on heuristic
 methods and often cannot provide the sufficient guarantees to developers, even
 if they admit soundness for all of their results.
 
 \subsection{Contributions}





\section{Preliminaries}

\subsection{Demonstrative Language}

We will build our tool for a language consisting of a small set of semantic rules (Figure \ref{fig:semrules}).

\begin{figure}
\caption{}
\label{fig:semrules}
\[
	\begin{array}{l l c l}
		\emph{Statement} & S & := & 
			\ \ A \\
			& & & |~ S_1\ ;\ S_2 \\
			& & & |~ \emph{if }p\emph{ then } S_1 \emph{ else } S_2 \\
			& & & |~ \emph{while }p\emph{ } S \\
		\emph{Predicate} & p &:=& \top ~~|~~ \bot ~~|~~ A ~~|~~ \lnot p ~~|~~ p \odot p \\
		\emph{Operator} & \odot &:=& \land ~~|~~ \lor \\
	\end{array}
\]
\end{figure}

Our results can be extended in a straightforward manner to an industrial language such as C, and we do so for our evaluation (Section \ref{sec:eval}).

\subsection{Taint Analysis}

Taint analysis is a standard program analysis technique, typically used to detect security vulnerabilities in either a static or dynamic manner. 
We restrict our focus to the static variant. We define a taint analysis algorithm as follows:

\begin{itemize}
    \item $\Gamma \gets \mathsf{Taint}_{S,L}(\phi, T, \Sigma, P)$: Takes as input an initial assignment $\phi$ of some taint sets $T = \{\tau_i\}$ to 
    a set of sources $\Sigma = \{\sigma_i\}$, and an input program $P$. Outputs an 
    assignment $\Gamma$ of statements $s_i$ in the program $P$ to taint sets $\tau_i \in T$ according to the taint propagation semantics $S$ for programming
    language $L$.
\end{itemize}


An example of static taint analysis is to determine if unsanitized user inputs are ever provided to vulnerable functions, such as SQL commands or
a webpage templating function. In our case we wish to ensure that entropy-sensitive inputs to cryptographic functions (sinks) can be
traced back to a high-entropy source such as *nix's \texttt{/dev/urandom}.

\subsection{$k$-safety properties}

As opposed to a safety property of a program (for example, ``variable $x$ is always positive'' or ``pointer $p$ is never null''), which requires
the absence of errors in a single program trace \cite{alpern1987recognizing}, a $k$-safety property of a program requires the absence of erroneous interactions between $k$
traces of the same program or single traces of $k$ different programs \cite{sousa2016cartesian}. A program property such as symmetry is a $2$-safety property. In the context of this
work we only consider $2$-safety properties.


\subsection{Predicate Abstraction}
\label{sec:predabstraction}

Predicate abstraction is a specialized form of abstract interpretation that can be used for checking $1$-safety properties of programs
\cite{flanagan2002predicate}. Abstract interpretation is a static analysis technique for programs that allows a verifier to, in some cases, 
automatically infer properties such as loop invariants. Formally we have:

\begin{itemize}
    \item $b \gets \mathsf{Verify}_{L}(\Pi, P)$: Takes as input a set $\Pi$ of $1$-safety properties and a program $P$ and outputs an accepting bit $\top$ if
    $P$ satisfies all $\pi \in \Pi$, and otherwise outputs a rejecting bit $\bot$ or fails to terminate otherwise.
\end{itemize}

CPAchecker \cite{beyer2011cpachecker} is an example of a state-of-the-art predicate abstraction verifier for the C programming language. In this work
we are interested in the safety property of equality. We note that due to inherent hardness results such as NP-hardness and undecidability, predicate
abstraction verifiers are based on heuristic methods and are not guaranteed to run in polynomial time, or even terminate.

\subsection{Product Programs}

The product $P_1 \times P_2$ of two programs $P_1$ and $P_2$ is not an entirely well-defined concept. In the most general sense, the product $P_1 \times P_2$ of 
two programs $P_1$ and $P_2$ is used to verify
relations between the programs, such as equivalence \cite{barthe2011relational}. Product programs have also been used to analyze different runs of the same program. 
The product program $P_1 \times P_2$ is semantically equivalent to the sequential composition $P_1; P_2$, but such that we can prove useful 
safety properties of $P_1 \times P_2$ that would be difficult to 
prove with standard techniques on $P_1$, $P_2$, or $P_1; P_2$.

For our purposes we simply require that $P_1 \times P_2$ is semantically
equivalent to the sequential composition $P_1\ ;\ P_2$ of the two programs. Our goal in using the concept of product programs is to aid the predicate abstraction
verifier. 

\section{Our Approach}

Our main approach to this problem is to take two versions $P_1$ and $P_2$ of a program and prove $P_2$ \emph{relative} to $P_1$. We have several
motivations for this approach:

\begin{itemize}
    \item Taint analysis is an (over)approximate solution.
    \item Modern software projects often use version control history, and we can leverage that to give a static verifier more power (heuristically speaking).
\end{itemize}

Let us address the first point.
An initial approach to this problem
might consist of using off-the-shelf taint analysis (we would taint high-entropy sources and confirm that
cryptographic functions receive high-entropy tainted inputs). 
However, taint analysis merely provides an overapproximation to the actual entropy that is
input to a cryptographic algorithm. Consider the program in Figure
\ref{fig:prog1}. The variable $k$ is tainted with high-entropy, but will not contain high-entropy if $f()$ ever evaluates to false.

\begin{figure}
    \caption{Taint analysis overapproximation}
    \label{fig:prog1}
    \begin{center}
    \begin{algorithmic}
        
        \If {$f()$}
        \State $k \gets$ \textsf{read(128, ``/dev/urandom'')}
        \Else
        \State $k \gets$ \textsf{getpid()}
        \EndIf
        \State $\mathsf{ctxt} \gets $ \textsf{AES}$(k,\mathsf{ptxt})$
    \end{algorithmic}
\end{center}
\end{figure}

Now we consider the second point. Since software developers often have access to multiple revisions of a single program, we wish to use this additional information
to do better than simple taint analysis on a single version. This allows for stronger security guarantees at lower cost: a software project can invest
in manually auditing an initial version of its security-critical software, and then use our methods to prove that subsequent versions do not contain entropy
failures provided that this initial version does not (i.e., a \emph{relative} or \emph{differential} notion of security). Additionally, since we expect
program revisions (particularly those touching security-critical components) to be infrequent and small, we can reduce the scope of the verifier's work.

\subsection{A First Attempt}

Given that we wish to attain this differential notion of security, we first address a naive attempt at solving this problem using taint analysis.
Consider the program in Figure \ref{fig:prog2} compared to the program in Figure \ref{fig:prog1}. The taint sets of $k$ in both versions of the program
are equal, however, simply comparing for equality here is \emph{unsound} with respect to our differential notion of security, since for all program traces
in which the first program is secure, all similar program traces in the second program are insecure.

\begin{figure}
    \caption{Taint analysis unsoundness}
    \label{fig:prog2}
    \begin{center}
    \begin{algorithmic}
        \If {$f()$}
        \State $k \gets$ \textsf{getpid()}
        \Else
        \State $k \gets$ \textsf{read(128, ``/dev/urandom'')}
        \EndIf
        \State $\mathsf{ctxt} \gets $ \textsf{AES}$(k,\mathsf{ptxt})$
    \end{algorithmic}
\end{center}
\end{figure}

\subsection{Differential Taint Analysis}

In this section, we introduce the notion of \emph{differential taint analysis}.
We consider two programs $P_1$ and $P_2$ with shared
source set $\Sigma$, taint set $T$, and sink set $Z$, and source-taint mapping $\phi$. 
A differential taint analysis algorithm
should accept only if for every program trace $\sigma_1$ and $\sigma_2$ of $P_1$
and $P_2$, respectively, on the same input $\vec{x}$ the taint set for all sinks
$\zeta_1 \in Z$ in $P_1$ are equal to the taint set for all sinks $\zeta_2 \in Z$ in $P_2$.
This notion is meant to capture the idea that if $P_1$ has all correct program traces,
$P_2$ will as well.

\subsection{Overview}

Our solution proceeds in three primary stages:

\begin{itemize}
    \item \textbf{Instrumentation:} In this step we reduce our taint analysis problem for each program version $P_1$ and $P_2$ to one of $2$-safety.
    Additionally, we run taint analysis on each program to get outputs $\Gamma_1$ and $\Gamma_2$, which we use in the next step.
    \item \textbf{Program synchronization:} Using our environment $\Gamma = \Gamma_1 \cup \Gamma_2$, our instrumented programs $P'_1$ and $P'_2$ from 
    the previous step, we construct the product program $P'_1 \times P'_2$. This converts the $2$-safety problem to one of $1$-safety.
    \item \textbf{Verification:} Finally, we pass $P'_1 \times P'_2$ to an off-the-shelf verifier to check the $1$-safety property to
    prove security.
\end{itemize}

We describe these in more formal detail in the coming sections.

\subsection{Instrumenting Programs for Predicate Abstraction}

	% Take C/C++ project and turn it into our IR. 

	In the instrumentation phase, we take an entire software project, and augment it with the other inputs (like annotations) to prepare it for the static analysis we will perform. Ultimately, our goal is to make assertions about the taintsets of program variables at the sinks. But first we will individually instrument each version of the software project.

	First we transform the code from its existing state into the language whose semantics we described earlier. We also rename the variables in the second version of the program so their names are disjoint from the variable names in program one. Then, in both programs, we replace the legitimate sources of entropy with labelled constants. We propogate these labelled constants through the program to propagate the taint of the entropy. In the process of doing so, it is possible that a value is tainted by more than one source (which is why we are tracking the taintset). We replace statements that taint a value with two or more sources ($s_1, s_2, \ldots, s_n$) with one of two uninterpreted functions: 

	\begin{enumerate}
		\item $\textsf{preserving}(s_1, s_2, \ldots, s_n)$ if the operation preserves entropy 
		\item $\textsf{non-preserving}(s_1, s_2, \ldots, s_n)$ if the operation does not preserve entropy 
	\end{enumerate}

	These uninterpreted functions are inferred to be pure functions over their variables, so they capture the notion of the taintset at that point. This allows us to assert their equality in the program we pass to CPAChecker. 

	Next, we will collect information from the two versions of the program as we transform them that will guide our future inference rules. Namely, we will perform taint analysis on sources to populate the environment $\Gamma$ which marks statements involving tainted variables. $\Gamma \vdash S_1$ if $S_1$ references a variable that is tainted by a source with sufficiently high entropy.  

	% Notice that if $x, y$ are both sufficiently entropic values then $x + y$ is also sufficiently entropic because the audition does not remove the entropy. Therefore addition is replaced with the $\textsf{preserving}$ function call. Contrast this with the left-shift, for example, which will remove entropy from the value. 

Formally, we propose the following algorithm:

\begin{itemize}
    \item $(\Gamma, P') \gets \mathsf{Instrument}(P, \mathsf{Taint}_{S,L}, \Sigma, \Delta)$: Given a program $P$, a taint analysis subroutine $\mathsf{Taint}_{S,L}$, a set
    of sources $\Sigma$, and a set of entropy-preserving operations $\Delta \subseteq \mathsf{Ops}$, we create a new program $P'$ in the following way. First,
    we compute $\Gamma \gets \mathsf{Taint}_{S,L}(\phi, \{\top\}, \Sigma, P)$ where $\phi$ is the membership function of $\Sigma$. Then:
    \begin{itemize}
        \item For each source $\sigma \in \Sigma$, replace with a labelled constant $c$.
        \item For all variables $x_i$ which are an assignment of a sequence of program variables $v_i$ and combined by operations $\odot \in \mathsf{Ops}$,
        if any $v_i$ is tainted and all operations are in $\Delta$ then assign $x_i$ to an uninterpreted function $\textsf{preserving}(v_1, \ldots, v_j)$. If
        any $v_i$ is tainted but one operations is not in $\Delta$, then assign $x_i$ to an uninterpreted function $\textsf{non-preserving}(v_1, \ldots, v_j)$.
        Otherwise, do nothing.
    \end{itemize}
    Output $\Gamma$ and $P'$.
\end{itemize}

We only consider operations known to preserve entropy such as addition (for example: over some modulus, like $\oplus$, or adding signed fixed-length integers, or arbitrary-precision) for inclusion in set $\Delta$.
Other operations, like bit-shifts, must be excluded from $\Delta$ to preserve security.

\subsection{Basic Product Program Inference Rules}
\label{sec:basicpprules}

With the instrumented programs, we can construct a product program that is semantically equivalent to the sequential composition of the two programs. However, we would like this product program to be more amenable to reason about for the static analysis tool. To this end, we would like to synchronize the control flow of the two programs as much as possible. 

We present inference rules for composing statements in the two programs $S_1 \cross S_1$ into one program that is semantically equivalent to $S_1\ ;\ S_2$. The most basic inference rule simply involves sequentially composing two atomic statements, which do not involve any control flow to be syncrhonized. Also, because the variables in the two versions of the program have been renamed to be disjoint, we can introduce an inference rule for the commutativity of two statements. See Figure \ref{fig:infrules1}.

\begin{figure}
    \caption{Basic Inference Rules}
    \label{fig:infrules1}
    \[
		\begin{array}{c}
			\infer[]{A_1 \cross A_2 \leadsto A_1\ ;\ A_2}{} \\ \\ \\
			\infer[]{S_1 \cross S_2 \leadsto P}{
				S_2 \cross S_1 \leadsto P
			}
        \end{array}
    \]
\end{figure}

Next, we have the inference rule for synchronizing an if-statement with another statement. If $S_1$ is the taken branch, $S_2$ is the not-taken branch, and $S$ is the statement after the entire if-else-statement, then we would like to inject $S$ separately into each branch. This simple transformation is clearly equivalent to the sequential composition of the if-statement and $S$. The benefit of this transformation, however, is that the predicate abstraction tool has more information about the trace taken with which it can reason about product program. See \ref{fig:infrules2}.

Finally, we have the inference rule for synchronizing two while loops. The intuition here is that we would like the two loops to operate in lock-step as long as possible. To maintain the equivalence with the sequential composition, we also run the remaining iterations in the leftover loop after the other loop's condition no longer holds. See \ref{fig:infrules2}.

\begin{figure}
    \caption{Conditional and Loop Inference Rules}
    \label{fig:infrules2}
    \[
		\begin{array}{c}
			\infer[]{if(p)\ then\ S_1\ else\ S_2 \cross S \leadsto P}{
				\text{$S_1 \cross S \leadsto S_1'$} \\
				\text{$S_2 \cross S \leadsto S_2'$} \\
				\text{$P = if(p)\ then\ S_1'\ else\ S_2'$}
			} \\ \\ \\
			\infer[]{while(p_1)\ S_1 \cross while(p_2)\ S_2 \leadsto P_0\ \cross\ P_1\ ;\ P_2}{
				\text{$P_0 = while(p_1 \land p_2)\ S_1\ ;\ S_2$} \\
				\text{$P_1 = while(p_1)\ S_1$} \\
				\text{$P_2 = while(p_2)\ S_2$}
			}
        \end{array}
    \]
\end{figure}

Although these inference rules are semantically equivalent to the sequential composition, and clearly provide benefit to CPAChecker, this proving strength comes at a cost. Namely, the if statements and the while loops lead to an exponential blowup in the size of the product program being reasoned about as a result of the copied statements. 

To demonstrate the application of these inference rules we will work an example. Consider the following two programs: Algorithm \ref{alg:p1} and \ref{alg:p2}.

\begin{algorithm}
  \caption{$P1$}
  \label{alg:p1}
  \begin{algorithmic}[1]
    \If {$p$}
        \State $x_1 \gets 1$
    \Else
        \State $x_1 \gets 2$
    \EndIf
  \end{algorithmic}
\end{algorithm}

and

\begin{algorithm}
  \caption{$P1$}
  \label{alg:p2}
  \begin{algorithmic}[1]
    \If {$p$}
        \State $x_1 \gets 2$
    \Else
        \State $x_1 \gets 1$
    \EndIf
  \end{algorithmic}
\end{algorithm}

These programs just switch the bodies of the if and else branches (so they are clearly not equivalent). 

Sequentially composed, we could imagine passing the following program to CPAChecker: Algorithm \ref{alg:seq}.

\begin{algorithm}
  \caption{$P1; P2$}
  \label{alg:seq}
  \begin{algorithmic}[1]
    \If {$p$}
        \State $x_1 \gets 1$
    \Else
        \State $x_1 \gets 2$
    \EndIf
    \If {$p$}
        \State $x_1 \gets 2$
    \Else
        \State $x_1 \gets 1$
    \EndIf
    \State \textsf{assert}$(x_1 == x_2)$
  \end{algorithmic}
\end{algorithm}

But instead, we could synchronize the if statements with the if-statement inference rule to yield: Algorithm \ref{alg:cross}.

\begin{algorithm}
  \caption{$P1{} \cross P2$}
  \label{alg:cross}
  \begin{algorithmic}[1]
    \If {$p$}
        \State $x_1 \gets 1$
        \If {$p$}
            \State $x_1 \gets 2$
        \Else
            \State $x_1 \gets 1$
        \EndIf
    \Else
        \State $x_1 \gets 2$
        \If {$p$}
            \State $x_1 \gets 2$
        \Else
            \State $x_1 \gets 1$
        \EndIf
    \EndIf
    \State \textsf{assert}$(x_1 == x_2)$
  \end{algorithmic}
\end{algorithm}

Clearly Algorithm \ref{alg:cross} is twice as long because we replicated $P2$ into both branches of the if-statement. However this is a tradeoff we may be willing to make in order to ease the burden on our predicate abstraction tool as compared to Algorithm \ref{alg:seq}.

\subsection{Taint-augmented Inference Rules}
\label{sec:augpprules}

We conjecture that the exponential blowup introduced by the naive inference rules is avoidable in some cases. In particular, our key insight is that we don't need the extra proving power provided by the synchronization in parts of the program that are unrelated to entropy. For these program statements, we can resort to the sequential composition. For example, consider a large software program: only a small portion of the code base will be related to the entropy. Therefore, we should concentrate the bulk of our analysis on this small portion of the code. 

We define these ``unrelated'' statements to be the ones that are not tainted by any legitimate entropy source. This is reasonable because our ultimate assertions we would like to prove will only be over the tainted variables. Thus, we can use the $\Gamma$ environment we constructed in the instrumentation step to augment our inference rules. We say that $\Gamma \vdash S$ if some variable referenced in $S$ is tainted by at least one legitimate source of entropy. Similarly, $\Gamma \nvdash S$ if no variable in the statement is tainted by any legitimate source of entropy. We introduce an optimization inference rule that does not lead to any exponential blowup for statements that are not entailed by $\Gamma$. See \ref{fig:auginfrules1}.

Formally, we define the following algorithm:

\begin{itemize}
    \item $P_1 \times P_2 \gets \mathsf{Prod}_R(P_1, P_2, \Gamma)$: Given two programs $P_1$ and $P_2$, a taint environment (mapping of program statements) to 
    taint values), and a set of inference rules $R$ we output the product program $P_1 \times P_2$.
\end{itemize}

\begin{figure}
    \caption{Augmented Inference Rules}
    \label{fig:auginfrules1}
    \[
		\begin{array}{c}
			\infer[]{\Gamma \vdash S_1 \cross S_2 \leadsto S_1\ ;\ S_2}{
				\Gamma \nvdash S_1 \\
				\Gamma \nvdash S_2
			} \\
		\end{array}
    \]
\end{figure}

Then, we can make the corresponding changes to our naive inference rules to recognize the $\Gamma$ environment we've introduced. This gives us the following set of augmented inference rules: See Figure \ref{fig:auginfrules2}.

\begin{figure}
    \caption{Augmented Inference Rules}
    \label{fig:auginfrules2}
    \[
		\begin{array}{c}
			\infer[]{\Gamma \vdash A_1 \cross A_2 \leadsto A_1\ ;\ A_2}{} \\ \\ \\
			\infer[]{\Gamma \vdash S_1 \cross S_2 \leadsto P}{
				\Gamma \vdash S_2 \cross S_1 \leadsto P
			} \\ \\ \\
			\infer[]{\Gamma \vdash S_1 \cross S_2 \leadsto S_1\ ;\ S_2}{
				\Gamma \nvdash S_1 \\
				\Gamma \nvdash S_2
			} \\ \\ \\
			\infer[]{\Gamma \vdash if(p)\ then\ S_1\ else\ S_2 \cross S \leadsto P}{
				\text{$\Gamma \vdash S_1 \cross S \leadsto S_1'$} \\
				\text{$\Gamma \vdash S_2 \cross S \leadsto S_2'$} \\
				\text{$P = if(p)\ then\ S_1'\ else\ S_2'$}
			} \\ \\ \\
			\infer[]{\Gamma \vdash while(p_1)\ S_1 \cross while(p_2)\ S_2 \leadsto P_0\ ;\ P_1\ ;\ P_2}{
				\text{$P_0 = while(p_1 \land p_2)\ S_1\ ;\ S_2$} \\
				\text{$P_1 = while(p_1)\ S_1$} \\
				\text{$P_2 = while(p_2)\ S_2$} \\
				\text{$P = if(p)\ then\ S_1'\ else\ S_2'$}
			}
		\end{array}
    \]
\end{figure}

% TODO: Notice that this optimization is only a heuristic. % (taint analysis isn't sufficient given the code snippet Isil mentioned). 

\subsection{Putting it all together}
\label{sec:all-together}

Let $\Delta$ be some set of entropy-preserving operations in our language $L$ with some set of 
natural taint propagation rules $S$.
Let $R$ be our set of inference rules described in Sections \ref{sec:basicpprules} and \ref{sec:augpprules}.
Using the subroutines we described above and the verification method in Section
\ref{sec:predabstraction}, we have the following algorithm:

\begin{itemize}
    \item $b \gets \mathsf{DifferentialTaintAnalysis}_\Delta(P_1, P_2, \Sigma, Z)$: We take 
    as input two programs $P_1$ and $P_2$, a set of sources $\Sigma$, and a set of 
    sinks $Z$. We then compute:
    \begin{itemize}
        \item $(\Gamma_1, P_1') \gets \mathsf{Instrument}(P_1, \mathsf{Taint}_{S,L}, \Sigma, \Delta)$
        \item $(\Gamma_2, P_2') \gets \mathsf{Instrument}(P_2, \mathsf{Taint}_{S,L}, \Sigma, \Delta)$
        \item $P'_1 \times P'_2 \gets \mathsf{Prod}_R(P'_1, P'_2, \Gamma_1 \cup \Gamma_2)$
    \end{itemize}
    At each synchronized sink pair $(\zeta_1, \zeta_2) \in Z$ in $P'_1 \times P'_2$, add an assertion of equality 
    $(\zeta_1 = \zeta_2)$ to a set of safety properties $\Pi$. Then compute $b \gets \mathsf{Verify}_{L}(\Pi, P'_1 \times P'_2)$
    and output $b$.
\end{itemize}

\section{Evaluation}
\label{sec:eval}

To evaluate the algorithm laid out in Section \ref{sec:all-together}, we utilized an off-the-shelf state-of-the-art predicate abstraction tool called CPAChecker \cite{beyer2011cpachecker}. This tool was selected because it was the winner in SV-COMP'18, the Competition on Software Verification. 

We demonstrated the motivating examples by writing a simple C program for each one and introducing entropy bugs to demonstrate possible issues. We selected C because most entropy bugs like the OpenSSL bug and the FreeBSD bug were implemented in systems level code written in C. Then, we instrumented these programs by replacing the sources and propagating them appropriately. After applying the inference rules to the composition of the original program and the buggy program, we ended up with a synchronized product program. We also applied the inference rules on the self-composition of the program to demonstrate version changes that don't introduce bugs that should be verified. The necessary assertions were inserted at the sinks after the product program was constructed.

By plugging these product programs into CPAChecker we were able to get the desired verification results. CPAChecker was able to successfully verify the correct changes and successfully fail on the incorrect changes. 

Note that our motivating examples were small and simple. Thus, the augmented inference rules evaluated to the same result as the naive inference rules. Our evaluation code snippets were correctly solved by CPAChecker in every variation of our inference rules: the sequential composition, the synchronized composition, and the augmented composition. Further evaluation is needed to confirm or reject our conjectures about the scalability of the various approaches in the design space and to explore the impact of our augmented inferene rules.

\section{Related Work}

In this section we explore a few other results in the area of differential or relational program verification.

\subsection{Differential assertion checking}

This paper generates relative specifications between multiple versions of the program, much in the same way we generate the relative specification between the taintsets of variables that flow into sinks. However, the differential assertion checking paper focuses on managing the number of warnings emitted by static analysis programs by using the correctness of previous versions to silence errors. In contrast, our approach aims to surface an entirely new class of warnings. See \cite{lahiri2013differential}.

\subsection{Secure information flow as a safety problem}
This paper explores the notion of applying type information of low-security types and high-security types to guide the inference rules in the construction of product programs. It paints a traditional 2-safety property of secure information flow as a 1-safety property by constructing the product program. Rather than using multiple versions of the same program like our approach, this paper explores the self-composition of one program, which is especially helpful for synchronizing statements when reducing from a 2-safety property. See  \cite{terauchi2005secure}.

\subsection{Relational verification using product programs}

This paper explores the inference rules needed to construct product programs for relational verification. Primarily, the inference rules synchronize loops in an effort to simplify the process of problems like inferring loop invariants to optimize the loops. Our work builds on this work by introducing the notion of using taint analysis environment to guide the inference rules. See \cite{barthe2011relational}.

\subsection{Verification modulo versions}

This paper leverages the multiple versions of a program to tackle the problem of spurious warnings in a sound way. It speaks to a larger trend of the hypothesis that multiple versions of a program generated in the software development lifecycle today can be capitalized by the static analysis community. See \cite{logozzo2014verification}.


\section{Future Work}

In continuing this work, we would like to pursue a couple of different lines of inquiries:

\begin{itemize}
    \item How much do our taint-augmented inference rules aid the verifier, from an experimental perspective on large projects such as OpenSSL?
    \item We wish to prove that our taint-augmented inferences rules (or some superset of them) are ``just as useful'' as the basic rules (that is,
    our verifier does not lose any information from using the scoped-down rules).
    \item We want a formal reduction between a notion of differential taint analysis and the approach described here.
    \item Create a push-button software solution for large projects, suitable for insertion in a continuous integration development cycle.
    \item Take an at-large survey of open-source software for entropy misuse vulnerabilities.
    \item What other security-related applications does differential taint analysis have?
\end{itemize}

\section{Conclusion}

In this work we present a new static analysis technique to aid in the prevention of entropy-misuse security vulnerabilities, such as those
found in the Debian OpenSSL and FreeBSD projects.

{\normalsize \bibliographystyle{acm}
\bibliography{refs}}

% \section{Considered Approaches}

% \subsection{Taint Analysis}
% Static code analysis has a history of identifying security vulnerabilities at a source code level. Some examples include SQL injection, cross-site scripting exploits, and buffer overflow attacks. However, there has not been any attempt in the literature to statically analyze source code for cryptographic vulnerabilities stemming from entropy misuse, which we seek to do. We claim that standard static code analysis techniques developed thus far are insufficient for the analysis we would like to perform. 
% The sources of entropy can be tainted standard taint analysis techniques can be used to approximate how the taint propagates. But this approximation may be too coarse to provide useful information to the user. Even with a sufficiently precise taint analysis, it is unclear how to determine the ``correct'' set of sources a cryptographic value should rely on at any point in the program.

% \subsection{Differential Taint Analysis}

% Since we want a stronger notion of taint analysis than a naive approach, we intend to introduce and formalize the concept of ``differential taint analysis." Differential
% taint analysis, in the ideal, will give us more information than simple taint analysis by leveraging 
% the original version of the program as a source of ground truth. This additional information could include reducing programmer annotation work or reduce false positives between versions
% (since taint analysis overapproximates data flow). By viewing the original version of the program as bug-free, we reduce the number of code audits required:
% only the original version of the code would need to be audited, and future versions could rely on our tool to automatically detect bugs that were introduced by refactors.

% \subsection{Product Programs}

% One technique that we have considered toward the construction of differential taint analysis is the notion of a ``product program.'' In the most general sense, the product $P_1 \times P_2$ of two programs $P_1$ and $P_2$ is used to verify
% relations between the programs, such as equivalence. Product programs have also been used to analyze different runs of the same program. 
% The product program $P_1 \times P_2$ is semantically equivalent to the sequential composition $P_1; P_2$, but such that we can prove useful safety properties of $P_1 \times P_2$ that would be difficult to prove with standard techniques on $P_1$, $P_2$, or $P_1; P_2$.

% In our setting, we are not so much interested in proving safety properties of a program $P$ but instead wish to prove that cryptographic values rely on sufficiently many bits of entropy when they are used via taint analysis, 
% which is why we cannot simply leverage existing off-the-shelf product program analysis techniques.

% \subsubsection{Example}

% Consider the following two programs $P_1$ and $P_2$ that are equivalent from a cryptographic point of view, but might have small feature changes. 

% \begin{algorithmic}
% \Function{$P_1$}{}
% \State $s \gets$ entropy
% \State $\vdots$
% \If {$p$}
% \State $c \gets$ AES(s)
% \EndIf
% \State $\vdots$
% \EndFunction
% \\
% \Function{$P_2$}{}
% \State $s \gets$ entropy
% \State $\vdots$
% \If {$p$}
% \State $c \gets$ AES(s)
% \EndIf
% \State $\vdots$
% \EndFunction
% \end{algorithmic}

% where $p$ is some complex predicate that is difficult to reason about, but does not change between $P_1$ and $P_2$ (and no values that $p$ depends on change, either). Then, a safety property about the entropy of the cryptographic values in $c$ would hold in both programs or in neither program. 

% Finally, even with a sufficiently precise taint analysis, it is unclear how to determine the ``correct'' set of sources a cryptographic value should rely on at any point in the program. For example, some programs will use weak entropy on system startup, and increase the entropy in those values, later on. Thus, by running our analysis on two versions of the program, we can use one version as an oracle for the correctness criteria of the other program. In other words, we can use it to infer what the set of taint results should be for any variable at any point in the program.  


% \section{Links}

% \begin{enumerate}
% 	\item Debian/OpenSSL Bug 
% 		\begin{enumerate}
% 			\item \url{https://www.schneier.com/blog/archives/2008/05/random_number_b.html}
% 			\item \url{https://research.swtch.com/openssl}
% 			\item \url{https://freedom-to-tinker.com/2013/09/20/software-transparency-debian-openssl-bug/}
% 			\item \url{https://www.cs.umd.edu/class/fall2017/cmsc818O/papers/private-keys-public.pdf}
% 		\end{enumerate}
% 	\item Data flow
% 		\begin{enumerate}
% 			\item \url{https://en.wikipedia.org/wiki/Data-flow_analysis}
% 			\item \url{https://www.seas.harvard.edu/courses/cs252/2011sp/slides/Lec02-Dataflow.pdf}
% 		\end{enumerate}
% 	\item Static Program Analysis
% 		\begin{enumerate}
%             \item \url{https://cs.au.dk/~amoeller/spa/spa.pdf}
%             \item \url{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6859783}
% 		\end{enumerate}
% 	\item Relational Verification:
% 		\begin{enumerate}
% 			\item \url{https://dl.acm.org/citation.cfm?id=2021319}
% 			\item \url{https://ac.els-cdn.com/S235222081630044X/1-s2.0-S235222081630044X-main.pdf?_tid=076a0492-9cee-4995-9710-bcb3c64b98e0&acdnat=1539815890_178849b4f14af3751e9acb03b238db4d}
% 			\item \url{https://www.microsoft.com/en-us/research/publication/differential-assertion-checking/}
% 			\item \url{https://www.microsoft.com/en-us/research/wp-content/uploads/2014/06/paper-1.pdf}
% 			\item \url{https://www.cs.utexas.edu/~isil/pldi16-chl.pdf}
% 		\end{enumerate}
% 	\item Projects to analyze 
% 		\begin{enumerate}
% 			\item OpenPGP
% 			\item BouncyCastle
% 			\item OpenSSL
% 			\item GnuPGP
% 			\item F\# SSL project with proof of correctness
% 			\item NQSBTLS
% 			\item Amazon's s2n (signal to noise)
% 		\end{enumerate}
% \end{enumerate}


% We have two motivating examples. First, we would like our tool to be able to detect the issue with the Debian/OpenSSL pseudo-random number generator that was exposed in 2008. 
% Second, we would like to identify potential vulnerabilities in current cryptocurrency wallet code as many cryptocurrency protocols rely on DSA.

% \subsection{Goals}
% We plan to use data dependency tools to determine how entropic inputs in a given program are used by various cryptographic algorithms. 
% That will allow us to identify if and when entropy is too low or is misused. We plan to either produce
% this as a code integration tool for developers to use as part of a compiler toolchain, or use this tool to analyze a large number of codebases
% found ``in the wild,'' such as those written by amateurs.

% Our tool will seek to generate a human-checkable dependency graph from source code
% using taint analysis on functions and function inputs manually specified via annotation by the developer.
% This graph will allow the developer to manually verify that entropy is used properly; a stretch goal 
% of ours would be to automate the identification of a subset of known misuses of entropy.

\end{document}
